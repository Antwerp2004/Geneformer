{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc204a32-7899-4e2c-9053-430e50b72d0b",
   "metadata": {},
   "source": [
    "# Data preparation for Geneformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e953108-5fd4-494b-b262-48be99c92870",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how to prepare dataset in `.dataset` format for inference tasks. We use the the pancreas dataset described in the [scIB Github](https://github.com/theislab/scib). The transformation procedures containing the 3 main steps:\n",
    "\n",
    "* Step 1: Convert gene name to Ensembl ID\n",
    "* Step 2: Convert data from Anndata to Loom\n",
    "* Step 3: Convert data from Loom to dataset\n",
    "\n",
    "Then, the resulting data format will be used in analysis with `Geneformer` from finetuning on cell-type annotation to gene classification and beyonds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df25345c-8d42-48cd-91d3-cf2ac781a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import loompy\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "from datasets import load_from_disk \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3c478-d0e5-454b-9e05-f3733e680591",
   "metadata": {},
   "source": [
    "## Step 1: Convert gene name to Ensembl ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c39ea1-69e5-4a76-9c54-f85e429c32c9",
   "metadata": {},
   "source": [
    "The current `AnnData` object uses gene names to indicate features on the gene expression matrix. However, `Geneformer` required `Ensembl ID` to indicate genes. Hence, the listed below codes will load the `AnnData` object and add the corresponding `Ensembl ID` of each gene to the `AnnData` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70500b5f-fd06-430d-a52c-68794c2a1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download dataset\n",
    "# !wget --timeout=0 --no-check-certificate 'https://s3.us-west-2.amazonaws.com/cdn.bioturing.com/colab/data/geneformer_data.zip'\n",
    "# !unzip -o geneformer_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886fb2d7-59be-43f0-af93-86385d339619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download gene annotation information from ebi\n",
    "# !wget  --timeout=0 --no-check-certificate https://s3.us-west-2.amazonaws.com/cdn.bioturing.com/colab/data/gencode.v44.annotation.gtf.gz\n",
    "\n",
    "# os.system(f\"/usr/bin/yes y | gunzip gencode.v44.annotation.gtf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94afdc40-e734-4895-b964-6461cc1535c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 16382 × 19093\n",
       "    obs: 'tech', 'celltype', 'size_factors', 'batch'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_h5ad = sc.read_h5ad('data/pancreas_scib.h5ad')\n",
    "data_h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de23eeaa-76e4-4d16-9c6e-60fa21e5131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map gene names to Ensembl IDs\n",
    "ensembl_mapping = {}\n",
    "with open('gencode.v44.annotation.gtf', 'r') as gtf_file:\n",
    "    for line in gtf_file:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        parts = line.strip().split('\\t')\n",
    "        if parts[2] == 'gene':\n",
    "            attributes = parts[-1].split('; ')\n",
    "            gene_name = None\n",
    "            gene_id = None\n",
    "            for attr in attributes:\n",
    "                if attr.startswith('gene_name'):\n",
    "                    gene_name = attr.split('\"')[1]\n",
    "                elif attr.startswith('gene_id'):\n",
    "                    gene_id = attr.split('\"')[1]\n",
    "            if gene_name and gene_id:\n",
    "                ensembl_mapping[gene_name] = gene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4f16b7-69b3-40b2-847c-17f83edd60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert gene names to Ensembl IDs\n",
    "def convert_gene_name_to_ensembl(gene_name):\n",
    "    return ensembl_mapping.get(gene_name, gene_name)  # Return the Ensembl ID if found, or the original gene name if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c958152c-c0c8-4517-82c8-be8f46b96ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the conversion function to the gene names in your AnnData object\n",
    "data_h5ad.var['ensembl_id'] = data_h5ad.var_names.map(convert_gene_name_to_ensembl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c9a450-b057-4afc-bb39-e41ab0c23481",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_h5ad.var['ensembl_id'])):\n",
    "    data_h5ad.var['ensembl_id'][i] = data_h5ad.var['ensembl_id'][i].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82794661-26aa-4098-8fa9-0106c99caf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1BG      ENSG00000121410\n",
       "A1CF      ENSG00000148584\n",
       "A2M       ENSG00000175899\n",
       "A2ML1     ENSG00000166535\n",
       "A4GALT    ENSG00000128274\n",
       "               ...       \n",
       "ZXDC      ENSG00000070476\n",
       "ZYG11B    ENSG00000162378\n",
       "ZYX       ENSG00000159840\n",
       "ZZEF1     ENSG00000074755\n",
       "ZZZ3      ENSG00000036549\n",
       "Name: ensembl_id, Length: 19093, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_h5ad.var['ensembl_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85155f51-53c6-462d-a5f6-25f12163ce17",
   "metadata": {},
   "source": [
    "Now, the AnnData object will have a new column `'ensembl_id'` with the Ensembl IDs. We can access it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c5eb9f-7b0d-4477-a585-b04c3d04e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_ids = data_h5ad.var['ensembl_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd3bd55e-bb37-4927-98b0-9f79ef0ae423",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_h5ad.var.index)):\n",
    "    data_h5ad.var.index.values[i] = ensembl_ids[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cdd229-9869-41c1-a18f-5d3d29e18485",
   "metadata": {},
   "source": [
    "We want to add another column indicating the number of genes in each cell in our analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a0600b4-ec87-4ed5-8617-761ca842a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_h5ad.obs[\"n_counts\"] = data_h5ad.obs.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "803e8d01-784c-4e21-9971-3e8c429a8b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D101_5         gamma\n",
       "D101_43        gamma\n",
       "D101_93        gamma\n",
       "D102_4         gamma\n",
       "D172444_23     gamma\n",
       "               ...  \n",
       "Sample_1594    gamma\n",
       "Sample_1595    gamma\n",
       "Sample_1597    gamma\n",
       "Sample_1598    gamma\n",
       "Sample_1600    gamma\n",
       "Name: celltype, Length: 16382, dtype: category\n",
       "Categories (14, object): ['acinar', 'activated_stellate', 'alpha', 'beta', ..., 'mast', 'quiescent_stellate', 'schwann', 't_cell']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_h5ad.obs.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dac78b4-9387-4fbc-aef0-627bd1047489",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_per_cell = np.sum(data_h5ad.X > 0, axis=1)\n",
    "\n",
    "# Create a new column in adata.obs to store the number of features per cell\n",
    "data_h5ad.obs['n_counts'] = num_features_per_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2990cea0-960a-4b60-b4ae-7c31d9b2e2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tech</th>\n",
       "      <th>celltype</th>\n",
       "      <th>size_factors</th>\n",
       "      <th>batch</th>\n",
       "      <th>n_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D101_5</th>\n",
       "      <td>celseq</td>\n",
       "      <td>gamma</td>\n",
       "      <td>0.028492</td>\n",
       "      <td>celseq</td>\n",
       "      <td>1857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D101_43</th>\n",
       "      <td>celseq</td>\n",
       "      <td>gamma</td>\n",
       "      <td>0.079348</td>\n",
       "      <td>celseq</td>\n",
       "      <td>3724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D101_93</th>\n",
       "      <td>celseq</td>\n",
       "      <td>gamma</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>celseq</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D102_4</th>\n",
       "      <td>celseq</td>\n",
       "      <td>gamma</td>\n",
       "      <td>0.047685</td>\n",
       "      <td>celseq</td>\n",
       "      <td>2653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D172444_23</th>\n",
       "      <td>celseq</td>\n",
       "      <td>gamma</td>\n",
       "      <td>0.038683</td>\n",
       "      <td>celseq</td>\n",
       "      <td>2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_1594</th>\n",
       "      <td>smarter</td>\n",
       "      <td>gamma</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>smarter</td>\n",
       "      <td>5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_1595</th>\n",
       "      <td>smarter</td>\n",
       "      <td>gamma</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>smarter</td>\n",
       "      <td>5196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_1597</th>\n",
       "      <td>smarter</td>\n",
       "      <td>gamma</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>smarter</td>\n",
       "      <td>6356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_1598</th>\n",
       "      <td>smarter</td>\n",
       "      <td>gamma</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>smarter</td>\n",
       "      <td>4170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_1600</th>\n",
       "      <td>smarter</td>\n",
       "      <td>gamma</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>smarter</td>\n",
       "      <td>4007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16382 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tech celltype  size_factors    batch  n_counts\n",
       "D101_5        celseq    gamma      0.028492   celseq      1857\n",
       "D101_43       celseq    gamma      0.079348   celseq      3724\n",
       "D101_93       celseq    gamma      0.037932   celseq      2261\n",
       "D102_4        celseq    gamma      0.047685   celseq      2653\n",
       "D172444_23    celseq    gamma      0.038683   celseq      2230\n",
       "...              ...      ...           ...      ...       ...\n",
       "Sample_1594  smarter    gamma      1.000000  smarter      5842\n",
       "Sample_1595  smarter    gamma      1.000000  smarter      5196\n",
       "Sample_1597  smarter    gamma      1.000000  smarter      6356\n",
       "Sample_1598  smarter    gamma      1.000000  smarter      4170\n",
       "Sample_1600  smarter    gamma      1.000000  smarter      4007\n",
       "\n",
       "[16382 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_h5ad.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291f044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51015b0a-c0e0-4e79-9b2a-6e8065365957",
   "metadata": {},
   "source": [
    "## Step 2: Convert data from AnnData to Loom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cb63f-c612-4182-8b77-93e15beb6e9d",
   "metadata": {},
   "source": [
    "By using `write_loom` function, we can convert data from `AnnData` to `Loom` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebcc2841-233f-4c6b-a4d2-e0ac2036ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_h5ad.write_loom(\"./pancreas_scib.loom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b070c2ed-7df9-40a7-8a58-5c6b390aa74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19093, 16382)\n",
      "['ensembl_id', 'var_names']\n",
      "['batch', 'celltype', 'n_counts', 'obs_names', 'size_factors', 'tech']\n",
      "[0.       3.311074 0.       ... 0.       0.       0.      ]\n",
      "19093\n"
     ]
    }
   ],
   "source": [
    "with loompy.connect('./pancreas_scib.loom') as ds:\n",
    "    # Add 'cell_type' and 'organ_major' to the loom file\n",
    "    print(ds.shape)\n",
    "    print(ds.ra.keys())\n",
    "    print(ds.ca.keys())\n",
    "    print(ds[:,2])\n",
    "    print(len(ds[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc701766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique cell types: 14\n",
      "Unique cell types:\n",
      "[np.str_('acinar'), np.str_('activated_stellate'), np.str_('alpha'), np.str_('beta'), np.str_('delta'), np.str_('ductal'), np.str_('endothelial'), np.str_('epsilon'), np.str_('gamma'), np.str_('macrophage'), np.str_('mast'), np.str_('quiescent_stellate'), np.str_('schwann'), np.str_('t_cell')]\n"
     ]
    }
   ],
   "source": [
    "import loompy\n",
    "\n",
    "with loompy.connect('./pancreas_scib.loom') as ds:\n",
    "    unique_celltypes = set(ds.ca[\"celltype\"])\n",
    "    print(f\"Number of unique cell types: {len(unique_celltypes)}\")\n",
    "    print(\"Unique cell types:\")\n",
    "    print(sorted(unique_celltypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f4afb-8917-41aa-b21d-c7821208dc1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T03:57:31.855531Z",
     "iopub.status.busy": "2023-11-06T03:57:31.855122Z",
     "iopub.status.idle": "2023-11-06T03:57:31.858755Z",
     "shell.execute_reply": "2023-11-06T03:57:31.858146Z",
     "shell.execute_reply.started": "2023-11-06T03:57:31.855505Z"
    }
   },
   "source": [
    "## Step 3: Convert data from Loom to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ffe70-fa02-4bbe-ac96-383a6365ff58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T03:58:37.356296Z",
     "iopub.status.busy": "2023-11-06T03:58:37.355496Z",
     "iopub.status.idle": "2023-11-06T03:58:37.364867Z",
     "shell.execute_reply": "2023-11-06T03:58:37.363963Z",
     "shell.execute_reply.started": "2023-11-06T03:58:37.356262Z"
    }
   },
   "source": [
    "We will use `TranscriptomeTokenizer` to convert dataset from `.loom` file to `.dataset`. This step also tokenizes our input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dab5901-b2a7-467c-ab90-ba4c29344250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cls> and <eos> are in gene_token_dict but special_token = False. Please note that for 95M model series, special_token should be True.\n"
     ]
    }
   ],
   "source": [
    "tk = TranscriptomeTokenizer(\n",
    "    {\n",
    "        \"batch\" : \"batch\", \n",
    "        \"celltype\" : \"celltype\", \n",
    "        \"n_counts\" : \"n_counts\", \n",
    "        \"obs_names\" : \"obs_names\", \n",
    "        \"size_factors\" : \"size_factors\", \n",
    "        \"tech\" : \"tech\"\n",
    "    }, \n",
    "    nproc=20, \n",
    "    model_input_size = 2048,\n",
    "    special_token=False # The 30M model series require the special_token argument to be set to False \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa3a967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row attrs: ['ensembl_id', 'var_names']\n",
      "Col attrs: ['batch', 'celltype', 'n_counts', 'obs_names', 'size_factors', 'tech']\n"
     ]
    }
   ],
   "source": [
    "import loompy\n",
    "\n",
    "loom_path = \"pancreas_scib.loom\"\n",
    "with loompy.connect(loom_path) as ds:\n",
    "    print(\"Row attrs:\", list(ds.ra.keys()))\n",
    "    print(\"Col attrs:\", list(ds.ca.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b4ab7c-b767-49ae-b714-a999f62b05d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing pancreas_scib__dedup.loom\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "'ensembl_id' column missing from data.ra.keys()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Output tokenized data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpancreas_scib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/geneformer_env/lib/python3.10/site-packages/geneformer/tokenizer.py:425\u001b[0m, in \u001b[0;36mTranscriptomeTokenizer.tokenize_data\u001b[0;34m(self, data_directory, output_directory, output_prefix, file_format, use_generator)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtokenize_data\u001b[39m(\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    402\u001b[0m     data_directory: Path \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m     use_generator: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    407\u001b[0m ):\n\u001b[1;32m    408\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m    Tokenize .loom files in data_directory and save as tokenized .dataset in output_directory.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     tokenized_cells, cell_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_directory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_format\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m     tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_dataset(\n\u001b[1;32m    429\u001b[0m         tokenized_cells,\n\u001b[1;32m    430\u001b[0m         cell_metadata,\n\u001b[1;32m    431\u001b[0m         use_generator\u001b[38;5;241m=\u001b[39muse_generator,\n\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    434\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m (Path(output_directory) \u001b[38;5;241m/\u001b[39m output_prefix)\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/geneformer_env/lib/python3.10/site-packages/geneformer/tokenizer.py:456\u001b[0m, in \u001b[0;36mTranscriptomeTokenizer.tokenize_files\u001b[0;34m(self, data_directory, file_format)\u001b[0m\n\u001b[1;32m    454\u001b[0m file_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m file_tokenized_cells, file_cell_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_file_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m tokenized_cells \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m file_tokenized_cells\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_attr_name_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/geneformer_env/lib/python3.10/site-packages/geneformer/tokenizer.py:551\u001b[0m, in \u001b[0;36mTranscriptomeTokenizer.tokenize_loom\u001b[0;34m(self, loom_file_path, target_sum)\u001b[0m\n\u001b[1;32m    548\u001b[0m loom_file_path_original \u001b[38;5;241m=\u001b[39m loom_file_path\n\u001b[1;32m    550\u001b[0m dedup_filename \u001b[38;5;241m=\u001b[39m loom_file_path\u001b[38;5;241m.\u001b[39mwith_name(loom_file_path\u001b[38;5;241m.\u001b[39mstem \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dedup.loom\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 551\u001b[0m loom_file_path \u001b[38;5;241m=\u001b[39m \u001b[43msum_ensembl_ids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloom_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollapse_gene_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgene_mapping_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgene_token_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_attr_name_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lp\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;28mstr\u001b[39m(loom_file_path)) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;66;03m# define coordinates of detected protein-coding or miRNA genes and vector of their normalization factors\u001b[39;00m\n\u001b[1;32m    563\u001b[0m     coding_miRNA_loc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m    564\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenelist_dict\u001b[38;5;241m.\u001b[39mget(i, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mra[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensembl_id_collapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    565\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/geneformer_env/lib/python3.10/site-packages/geneformer/tokenizer.py:101\u001b[0m, in \u001b[0;36msum_ensembl_ids\u001b[0;34m(data_directory, collapse_gene_ids, gene_mapping_dict, gene_token_dict, custom_attr_name_dict, file_format, chunk_size)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03mMap Ensembl IDs from gene mapping dictionary. If duplicate Ensembl IDs are found, sum counts together.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lp\u001b[38;5;241m.\u001b[39mconnect(data_directory) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensembl_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mra\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    102\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensembl_id\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column missing from data.ra.keys()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensembl_id_collapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mra\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    106\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensembl_id_collapsed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column already exists in data.ra.keys()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mca\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    110\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_counts\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column missing from data.ca.keys()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 'ensembl_id' column missing from data.ra.keys()"
     ]
    }
   ],
   "source": [
    "# Output tokenized data\n",
    "tk.tokenize_data(\n",
    "    data_directory=\"./\",\n",
    "    output_directory=\"./data\",\n",
    "    output_prefix=\"pancreas_scib\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4cb5e4-fe46-45b5-bac3-9746c2e2a316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T03:59:34.070401Z",
     "iopub.status.busy": "2023-11-06T03:59:34.069326Z",
     "iopub.status.idle": "2023-11-06T03:59:34.073538Z",
     "shell.execute_reply": "2023-11-06T03:59:34.072917Z",
     "shell.execute_reply.started": "2023-11-06T03:59:34.070366Z"
    }
   },
   "source": [
    "## Load and check the input `.dataset` after tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de167737-a336-470f-9b96-865d0bdabc49",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory ./data/pancreas_scib.dataset/ is neither a `Dataset` directory nor a `DatasetDict` directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/pancreas_scib.dataset/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(token_dataset))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(token_dataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/geneformer_env/lib/python3.10/site-packages/datasets/load.py:2148\u001b[0m, in \u001b[0;36mload_from_disk\u001b[0;34m(dataset_path, keep_in_memory, storage_options)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict\u001b[38;5;241m.\u001b[39mload_from_disk(dataset_path, keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   2149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is neither a `Dataset` directory nor a `DatasetDict` directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2150\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory ./data/pancreas_scib.dataset/ is neither a `Dataset` directory nor a `DatasetDict` directory."
     ]
    }
   ],
   "source": [
    "token_dataset = load_from_disk(\"./data/pancreas_scib.dataset/\")\n",
    "print(type(token_dataset))\n",
    "print(token_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9671d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(token_dataset[\"celltype\"]))\n",
    "# print(token_dataset[\"celltype\"])\n",
    "\n",
    "unique_cell_types = set(token_dataset[\"celltype\"])\n",
    "print(unique_cell_types) # 14 cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter leaving only specific cell types\n",
    "cell_types_to_keep = [\"t_cell\", \"macrophage\", \"endothelial\", \"acinar\"]\n",
    "filtered_dataset = token_dataset.filter(lambda f: f[\"celltype\"] in cell_types_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ecac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_dataset)\n",
    "print(type(filtered_dataset))\n",
    "\n",
    "unique_filtered_cell_types = set(filtered_dataset[\"celltype\"])\n",
    "print(unique_filtered_cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered dataset to disk\n",
    "filtered_dataset.save_to_disk(\"./data/pancreas_scib_filtered.dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a60224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the filtered dataset and check the cell types\n",
    "loaded_filtered_dataset = load_from_disk(\"./data/pancreas_scib_filtered.dataset/\")\n",
    "print(loaded_filtered_dataset)\n",
    "print(loaded_filtered_dataset.shape)\n",
    "print(loaded_filtered_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56e18d-ae20-40e7-a2d5-2e2ed19aa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_dataset)\n",
    "print(token_dataset.shape)\n",
    "print(token_dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
